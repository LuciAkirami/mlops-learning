{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-08-29 16:26:34--  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-01.parquet\n",
      "Resolving d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)... 3.164.82.112, 3.164.82.197, 3.164.82.40, ...\n",
      "Connecting to d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)|3.164.82.112|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 21686067 (21M) [application/x-www-form-urlencoded]\n",
      "Saving to: ‘/workspaces/mlops-learning/01-intro/data/yellow_tripdata_2021-01.parquet’\n",
      "\n",
      "yellow_tripdata_202 100%[===================>]  20.68M  15.5MB/s    in 1.3s    \n",
      "\n",
      "2024-08-29 16:26:35 (15.5 MB/s) - ‘/workspaces/mlops-learning/01-intro/data/yellow_tripdata_2021-01.parquet’ saved [21686067/21686067]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Downloading the dataset\n",
    "!wget https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet -P /workspaces/mlops-learning/01-intro/data\n",
    "!wget https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-02.parquet -P /workspaces/mlops-learning/01-intro/data\n",
    "\n",
    "\n",
    "# Download 2021 data\n",
    "!wget https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-01.parquet -P /workspaces/mlops-learning/01-intro/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the indepth version of Training and Prediction, check 01-intro folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the necesasry libraries\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to read the data, preprocess it and return it\n",
    "def read_and_preprocess(filename):\n",
    "    data = pd.read_parquet(filename)\n",
    "    \n",
    "    # create the target variable\n",
    "    data['ride_duration'] = data['tpep_dropoff_datetime'] - data['tpep_pickup_datetime'] \n",
    "    data['ride_duration'] = data['ride_duration'].apply(lambda x: x.total_seconds()/60) \n",
    "\n",
    "    # take only the data below 1 hour\n",
    "    data = data[(data['ride_duration'] >= 1) & (data['ride_duration'] <= 60)]\n",
    "\n",
    "    # sample the data to 70k rows\n",
    "    sampled_data = data.iloc[:70000,:].copy()\n",
    "    \n",
    "    # chosing categorical\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "\n",
    "    # convert these numerical categorical features to string categorical features\n",
    "    sampled_data[categorical] = sampled_data[categorical].astype(str)\n",
    "\n",
    "\n",
    "    return sampled_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_data = read_and_preprocess('/workspaces/mlops-learning/01-intro/data/yellow_tripdata_2024-01.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chosing categorical and numerical features\n",
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "numerical = ['trip_distance']\n",
    "\n",
    "# creating the training data with the features\n",
    "train_data = sampled_data[categorical + numerical]\n",
    "\n",
    "# storing our target variable\n",
    "target = 'ride_duration'\n",
    "y_train = sampled_data[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 210000 stored elements and shape (70000, 447)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to use the DictVectorizer, we need to convert the dataframe to dict\n",
    "train_dicts = train_data.to_dict(orient='records')\n",
    "\n",
    "dv = DictVectorizer()\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(5.797042749628479)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a LinearRegression Model\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on train data\n",
    "y_pred = lr.predict(X_train)\n",
    "\n",
    "# calculate the metrics\n",
    "root_mean_squared_error(y_train, y_pred) # squared set to False implies we are using RMSE instead MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# sns.displot(y_train, kde=True, stat='density',kde_kws=dict(cut=3), label='Actual')\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# sns.displot(y_pred, kde=True, stat='density',kde_kws=dict(cut=3), label='Predicted') \u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# sns.distplot(y_train, kde=True, label='Actual')\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# sns.distplot(y_pred, kde=True, label='Predicted') \u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m sns\u001b[38;5;241m.\u001b[39mkdeplot(\u001b[43my_train\u001b[49m,label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActual\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m sns\u001b[38;5;241m.\u001b[39mkdeplot(y_pred,label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "# sns.displot(y_train, kde=True, stat='density',kde_kws=dict(cut=3), label='Actual')\n",
    "# sns.displot(y_pred, kde=True, stat='density',kde_kws=dict(cut=3), label='Predicted') \n",
    "\n",
    "# sns.distplot(y_train, kde=True, label='Actual')\n",
    "# sns.distplot(y_pred, kde=True, label='Predicted') \n",
    "\n",
    "sns.kdeplot(y_train,label='Actual')\n",
    "sns.kdeplot(y_pred,label='Predicted') \n",
    "\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold Cross Valiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation RMSE: [5.87214604 5.94142789 5.96554232 5.80563044 5.80900893]\n",
      "Average Cross-Validation RMSE: 5.87875112379174\n"
     ]
    }
   ],
   "source": [
    "# Convert the dataset to dictionaries\n",
    "train_dicts = train_data.to_dict(orient='records')\n",
    "\n",
    "# Vectorize the data\n",
    "dv = DictVectorizer()\n",
    "X = dv.fit_transform(train_dicts)\n",
    "y = sampled_data['ride_duration'].values\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Set up 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_rmse = np.sqrt(-cross_val_score(lr, X, y, cv=kf, scoring='neg_mean_squared_error'))\n",
    "\n",
    "print(f'Cross-Validation RMSE: {cv_rmse}')\n",
    "print(f'Average Cross-Validation RMSE: {cv_rmse.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scoring='neg_mean_squared_error'`: This tells cross_val_score to evaluate the model using the Negative Mean Squared Error (MSE) as the scoring metric. The reason for using \"negative\" MSE is that cross_val_score by default assumes higher scores are better, so negative values allow it to maintain consistency (since MSE is a loss function, lower is better).\n",
    "\n",
    "`-cross_val_score(...):`\n",
    "\n",
    "The scores returned by cross_val_score are negative because of the `neg_mean_squared_error` scoring. By negating them (multiplying by -1), you get the actual Mean Squared Error (MSE) values for each fold. If it's negative we cannot take the square root of it\n",
    "\n",
    "MSE is the average of the squared differences between the predicted and actual values. RMSE is the square root of the MSE, which is more interpretable because it’s in the same units as the target variable (ride_duration in this case).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation RMSE: [0.82801636 0.81976742 0.82515868 0.82878804 0.83299871]\n",
      "Average Cross-Validation RMSE: 0.826945840395376\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation - Without Scoring Variable\n",
    "# if scoring is not mentioned, the default score func of estimator will be used\n",
    "# the default scorer for LinearReg is R Square i.e. (1 - u/v), where\n",
    "# \"u\" is he residual sum of squares ((y_true - y_pred)** 2).sum() and is the total sum of squares ((y_true - y_true.mean()) ** 2).sum()\n",
    "# and the best possible score is 1.0 and worst is 0\n",
    "cv_rmse = np.sqrt(cross_val_score(lr, X, y, cv=kf))\n",
    "\n",
    "print(f'Cross-Validation RMSE: {cv_rmse}')\n",
    "print(f'Average Cross-Validation RMSE: {cv_rmse.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
