{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the necesasry libraries\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/137411656770551778', creation_time=1725021597969, experiment_id='137411656770551778', last_update_time=1725021597969, lifecycle_stage='active', name='taxi-prediction-model-management', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Set our tracking server uri for logging\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000\")\n",
    "\n",
    "# Create a new MLflow Experiment - Inside an experiment, there will be Runs\n",
    "mlflow.set_experiment(\"taxi-prediction-model-management\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to read the data, preprocess it and return it\n",
    "def read_and_preprocess(filename):\n",
    "    data = pd.read_parquet(filename)\n",
    "    \n",
    "    # create the target variable\n",
    "    data['ride_duration'] = data['tpep_dropoff_datetime'] - data['tpep_pickup_datetime'] \n",
    "    data['ride_duration'] = data['ride_duration'].apply(lambda x: x.total_seconds()/60) \n",
    "\n",
    "    # take only the data below 1 hour\n",
    "    data = data[(data['ride_duration'] >= 1) & (data['ride_duration'] <= 60)]\n",
    "\n",
    "    # # sample the data to 70k rows\n",
    "    # if len(data) > 70000:\n",
    "    #     sampled_data = data.iloc[:70000,:].copy()\n",
    "    # else:\n",
    "    #     sampled_data = data.copy()\n",
    "    sampled_data = data.copy()\n",
    "    \n",
    "    # chosing categorical\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "\n",
    "    # convert these numerical categorical features to string categorical features\n",
    "    sampled_data[categorical] = sampled_data[categorical].astype(str)\n",
    "\n",
    "\n",
    "    return sampled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When using GitHub CodeSpaces - Path is Set according to that\n",
    "# df_train = read_and_preprocess('/workspaces/mlops-learning/01-intro/data/yellow_tripdata_2021-01.parquet')\n",
    "# df_valid = read_and_preprocess('/workspaces/mlops-learning/01-intro/data/yellow_tripdata_2021-02.parquet')\n",
    "\n",
    "# when not using GitHub CodeSpaces\n",
    "df_train = read_and_preprocess('../01-intro/data/yellow_tripdata_2021-01.parquet')\n",
    "df_valid = read_and_preprocess('../01-intro/data/yellow_tripdata_2021-02.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chosing categorical and numerical features\n",
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "numerical = ['trip_distance']\n",
    "\n",
    "# to use the DictVectorizer, we need to convert the dataframe to dict\n",
    "train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "val_dicts = df_valid[categorical + numerical].to_dict(orient='records')\n",
    "\n",
    "\n",
    "dv = DictVectorizer()\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "X_valid = dv.fit_transform(val_dicts)\n",
    "\n",
    "# storing our target variable\n",
    "target = 'ride_duration'\n",
    "y_train = df_train[target].values\n",
    "y_val = df_valid[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = xgb.DMatrix(X_train, label=y_train)\n",
    "valid = xgb.DMatrix(X_valid, label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:6.67760\n",
      "[1]\tvalidation-rmse:5.43694\n",
      "[2]\tvalidation-rmse:4.91329\n",
      "[3]\tvalidation-rmse:4.70343\n",
      "[4]\tvalidation-rmse:4.61204\n",
      "[5]\tvalidation-rmse:4.57421\n",
      "[6]\tvalidation-rmse:4.55375\n",
      "[7]\tvalidation-rmse:4.54199\n",
      "[8]\tvalidation-rmse:4.53226\n",
      "[9]\tvalidation-rmse:4.51629\n",
      "[10]\tvalidation-rmse:4.51067\n",
      "[11]\tvalidation-rmse:4.50948\n",
      "[12]\tvalidation-rmse:4.51238\n",
      "[13]\tvalidation-rmse:4.50975\n",
      "[14]\tvalidation-rmse:4.50785\n",
      "[15]\tvalidation-rmse:4.50801\n",
      "[16]\tvalidation-rmse:4.50526\n",
      "[17]\tvalidation-rmse:4.49809\n",
      "[18]\tvalidation-rmse:4.50009\n",
      "[19]\tvalidation-rmse:4.50017\n",
      "[20]\tvalidation-rmse:4.49735\n",
      "[21]\tvalidation-rmse:4.50112\n",
      "[22]\tvalidation-rmse:4.50302\n",
      "[23]\tvalidation-rmse:4.49901\n",
      "[24]\tvalidation-rmse:4.50344\n",
      "[25]\tvalidation-rmse:4.50533\n",
      "[26]\tvalidation-rmse:4.50451\n",
      "[27]\tvalidation-rmse:4.50134\n",
      "[28]\tvalidation-rmse:4.50144\n",
      "[29]\tvalidation-rmse:4.49909\n"
     ]
    }
   ],
   "source": [
    "# these parameters are taken after running the above cell and\n",
    "# checking which parameters got the best rmse\n",
    "params = {\n",
    "    'max_depth': 36,\n",
    "    'learning_rate': 0.4,\n",
    "    'reg_alpha': 0.015,\n",
    "    'reg_lambda': 0.0053,\n",
    "    'min_child_weight': 15.88,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# we provide the autolog here, just before the run function which gets executed in objective function\n",
    "# mlflow.xgboost.autolog() \n",
    "\n",
    "# so the objective will be called 10 times and for each time, a run will be registered in the MLFlow\n",
    "booster = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=train,\n",
    "            num_boost_round=100,\n",
    "            evals=[(valid, 'validation')],\n",
    "            early_stopping_rounds=10\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we provide the autolog here, just before the run function which gets executed in objective function\n",
    "mlflow.xgboost.autolog() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/30 12:50:06 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'cf498044cda94b008bc35b21541095c3', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current xgboost workflow\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# these parameters are taken after running the above cell and\n",
    "# checking which parameters got the best rmse\n",
    "params = {\n",
    "    'max_depth': 36,\n",
    "    'learning_rate': 0.4,\n",
    "    'reg_alpha': 0.015,\n",
    "    'reg_lambda': 0.0053,\n",
    "    'min_child_weight': 15.88,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# so the objective will be called 10 times and for each time, a run will be registered in the MLFlow\n",
    "booster = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=train,\n",
    "            num_boost_round=100,\n",
    "            evals=[(valid, 'validation')],\n",
    "            early_stopping_rounds=10\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
