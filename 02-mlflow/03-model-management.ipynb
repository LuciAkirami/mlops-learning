{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the necesasry libraries\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Downloading the dataset - Run When using GitHub, as the download path is based on GitHUb CodeSpaces\n",
    "# !wget https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet -P /workspaces/mlops-learning/01-intro/data\n",
    "# !wget https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-02.parquet -P /workspaces/mlops-learning/01-intro/data\n",
    "\n",
    "\n",
    "# # Download 2021 data\n",
    "# !wget https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-01.parquet -P /workspaces/mlops-learning/01-intro/data\n",
    "# !wget https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-02.parquet -P /workspaces/mlops-learning/01-intro/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/30 19:35:23 INFO mlflow.tracking.fluent: Experiment with name 'taxi-model-management' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/479749850566603769', creation_time=1725026723957, experiment_id='479749850566603769', last_update_time=1725026723957, lifecycle_stage='active', name='taxi-model-management', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Set our tracking server uri for logging\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000\")\n",
    "\n",
    "# Create a new MLflow Experiment - Inside an experiment, there will be Runs\n",
    "mlflow.set_experiment(\"taxi-model-management\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to read the data, preprocess it and return it\n",
    "def read_and_preprocess(filename):\n",
    "    data = pd.read_parquet(filename)\n",
    "    \n",
    "    # create the target variable\n",
    "    data['ride_duration'] = data['tpep_dropoff_datetime'] - data['tpep_pickup_datetime'] \n",
    "    data['ride_duration'] = data['ride_duration'].apply(lambda x: x.total_seconds()/60) \n",
    "\n",
    "    # take only the data below 1 hour\n",
    "    data = data[(data['ride_duration'] >= 1) & (data['ride_duration'] <= 60)]\n",
    "\n",
    "    # # sample the data to 70k rows\n",
    "    # if len(data) > 70000:\n",
    "    #     sampled_data = data.iloc[:70000,:].copy()\n",
    "    # else:\n",
    "    #     sampled_data = data.copy()\n",
    "    sampled_data = data.copy()\n",
    "    \n",
    "    # chosing categorical\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "\n",
    "    # convert these numerical categorical features to string categorical features\n",
    "    sampled_data[categorical] = sampled_data[categorical].astype(str)\n",
    "\n",
    "\n",
    "    return sampled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When using GitHub CodeSpaces - Path is Set according to that\n",
    "# df_train = read_and_preprocess('/workspaces/mlops-learning/01-intro/data/yellow_tripdata_2021-01.parquet')\n",
    "# df_valid = read_and_preprocess('/workspaces/mlops-learning/01-intro/data/yellow_tripdata_2021-02.parquet')\n",
    "\n",
    "# when not using GitHub CodeSpaces\n",
    "df_train = read_and_preprocess('../01-intro/data/yellow_tripdata_2021-01.parquet')\n",
    "df_valid = read_and_preprocess('../01-intro/data/yellow_tripdata_2021-02.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chosing categorical and numerical features\n",
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "numerical = ['trip_distance']\n",
    "\n",
    "# to use the DictVectorizer, we need to convert the dataframe to dict\n",
    "train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "val_dicts = df_valid[categorical + numerical].to_dict(orient='records')\n",
    "\n",
    "\n",
    "dv = DictVectorizer()\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "X_valid = dv.fit_transform(val_dicts)\n",
    "\n",
    "# storing our target variable\n",
    "target = 'ride_duration'\n",
    "y_train = df_train[target].values\n",
    "y_val = df_valid[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = xgb.DMatrix(X_train, label=y_train)\n",
    "valid = xgb.DMatrix(X_valid, label=y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto Logging for XGBoost Fails for a Reason - Crashing the Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # these parameters are taken after running the above cell and\n",
    "# # checking which parameters got the best rmse\n",
    "# params = {\n",
    "#     'max_depth': 36,\n",
    "#     'learning_rate': 0.4,\n",
    "#     'reg_alpha': 0.015,\n",
    "#     'reg_lambda': 0.0053,\n",
    "#     'min_child_weight': 15.88,\n",
    "#     'seed': 42\n",
    "# }\n",
    "\n",
    "# # we provide the autolog here, just before the run function which gets executed in objective function\n",
    "# # mlflow.xgboost.autolog() \n",
    "\n",
    "# booster = xgb.train(\n",
    "#             params=params,\n",
    "#             dtrain=train,\n",
    "#             num_boost_round=100,\n",
    "#             evals=[(valid, 'validation')],\n",
    "#             early_stopping_rounds=10\n",
    "#         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the Model\n",
    "\n",
    "We can save the model in two ways\n",
    "\n",
    "- Log model as an artifact\n",
    "- Log model using the method log_method\n",
    "\n",
    "log_method stores more information about the model that is being saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:6.67760\n",
      "[1]\tvalidation-rmse:5.43694\n",
      "[2]\tvalidation-rmse:4.91329\n",
      "[3]\tvalidation-rmse:4.70343\n",
      "[4]\tvalidation-rmse:4.61204\n",
      "[5]\tvalidation-rmse:4.57421\n",
      "[6]\tvalidation-rmse:4.55375\n",
      "[7]\tvalidation-rmse:4.54199\n",
      "[8]\tvalidation-rmse:4.53226\n",
      "[9]\tvalidation-rmse:4.51629\n",
      "[10]\tvalidation-rmse:4.51067\n",
      "[11]\tvalidation-rmse:4.50948\n",
      "[12]\tvalidation-rmse:4.51238\n",
      "[13]\tvalidation-rmse:4.50975\n",
      "[14]\tvalidation-rmse:4.50785\n",
      "[15]\tvalidation-rmse:4.50801\n",
      "[16]\tvalidation-rmse:4.50526\n",
      "[17]\tvalidation-rmse:4.49809\n",
      "[18]\tvalidation-rmse:4.50009\n",
      "[19]\tvalidation-rmse:4.50017\n",
      "[20]\tvalidation-rmse:4.49735\n",
      "[21]\tvalidation-rmse:4.50112\n",
      "[22]\tvalidation-rmse:4.50302\n",
      "[23]\tvalidation-rmse:4.49901\n",
      "[24]\tvalidation-rmse:4.50344\n",
      "[25]\tvalidation-rmse:4.50533\n",
      "[26]\tvalidation-rmse:4.50451\n",
      "[27]\tvalidation-rmse:4.50134\n",
      "[28]\tvalidation-rmse:4.50144\n",
      "[29]\tvalidation-rmse:4.49909\n",
      "[30]\tvalidation-rmse:4.50055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/topisano/Desktop/projects/mlops-learning/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [19:45:22] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2024/08/30 19:45:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/08/30 19:45:23 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run selective-goat-726 at: http://127.0.0.1:5000/#/experiments/479749850566603769/runs/d0550e2a887d4a7e99cf6f989a3bca5e.\n",
      "2024/08/30 19:45:23 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/479749850566603769.\n"
     ]
    }
   ],
   "source": [
    "# these parameters are taken after running the above cell and\n",
    "# checking which parameters got the best rmse\n",
    "params = {\n",
    "    'max_depth': 36,\n",
    "    'learning_rate': 0.4,\n",
    "    'reg_alpha': 0.015,\n",
    "    'reg_lambda': 0.0053,\n",
    "    'min_child_weight': 15.88,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# starting the run\n",
    "with mlflow.start_run():\n",
    "    mlflow.set_tag(\"model\",'XGBoost')\n",
    "\n",
    "    # logging the parameters\n",
    "    mlflow.log_params(params)\n",
    "    \n",
    "    booster = xgb.train(\n",
    "                params=params,\n",
    "                dtrain=train,\n",
    "                num_boost_round=100,\n",
    "                evals=[(valid, 'validation')],\n",
    "                early_stopping_rounds=10\n",
    "            )\n",
    "    \n",
    "    y_pred = booster.predict(valid)\n",
    "\n",
    "    # logging the predictions\n",
    "    rmse = root_mean_squared_error(y_val, y_pred)\n",
    "    mlflow.log_metric('rmse',rmse)\n",
    "\n",
    "    # create a folder models\n",
    "    # saving the preprocessor to the models folder\n",
    "    with open('models/preprocessor.b', 'wb') as f_out:\n",
    "        pickle.dump(dv, f_out)\n",
    "\n",
    "    # log the saved preprocessor\n",
    "    mlflow.log_artifact('models/preprocessor.b','preprocessor')\n",
    "\n",
    "    # saving the model - creates a folder and stores the model in that folder\n",
    "    # a folder called mlartifacts is created. Inside this folder, there is an artifact\n",
    "    # folder and inside that folder, the models_mlflow folder is created\n",
    "    mlflow.xgboost.log_model(booster, artifact_path='models_mlflow')\n",
    "\n",
    "# inside the models_mlflow folder there wil be following files\n",
    "# - MLmodel -> Contains the overview info about the below\n",
    "# - conda.yaml -> contains info about how to run the model with conda\n",
    "# - model.xgb -> the actual model\n",
    "# - python_env.yaml -> contains the information of build dependencide\n",
    "# - requirements.txt -> contains all the library names to be installed to run the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, with the above cell, we were able to create a model, log its metrics, finally log the model and preprocess to the mlfow artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Model \n",
    "\n",
    "We can load the model in two flavours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flavour 1 / Method 1\n",
    "\n",
    "- In this approach we use the model as a python object from mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 36.20it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mlflow.pyfunc.loaded_model:\n",
       "  artifact_path: models_mlflow\n",
       "  flavor: mlflow.xgboost\n",
       "  run_id: d0550e2a887d4a7e99cf6f989a3bca5e"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the model URI, this is unique to each run. Everytime we\n",
    "# run the above training cell, a new URI will be generated, i.e. a new model will be saved\n",
    "logged_model = 'runs:/d0550e2a887d4a7e99cf6f989a3bca5e/models_mlflow'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "# we see that its an object of type pyfunction\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(4.50055089347854)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = loaded_model.predict(X_valid)\n",
    "\n",
    "root_mean_squared_error(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flavour 2 \n",
    "\n",
    "- In this approach, we load the model directly as a XGBoost Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 35.01it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<xgboost.core.Booster at 0x75b4bd932bd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call the xgboost load_method and pass the URI\n",
    "xgboost_model = mlflow.xgboost.load_model(logged_model)\n",
    "\n",
    "# we see that now we have an object of type XGBoost\n",
    "xgboost_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(4.50055089347854)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = xgboost_model.predict(valid)\n",
    "\n",
    "root_mean_squared_error(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information about both of these flavours are found in the file MLModel in the models_mlflow folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
