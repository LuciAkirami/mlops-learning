{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When came with a new model. We want to ask some questions. Like what has changed from previous version of model to new version. Is there any preprocessing needed? What are extra libraries that we need to run a new model\n",
    "\n",
    "And what if when running this new model in production we face some issues and roll back to old model. We need to know where the old model is stored\n",
    "\n",
    "When doing an ML task, we use the MLFlow Tracking Server to log the parameters, metrics, artifactions and also many different model versions\n",
    "\n",
    "Once we believe those models are fit for production, then we will \"register model\" to the MLFlow registry\n",
    "\n",
    "MLFlow registry is the place where we store the production ready models. So whenver a deployment engineer wants to update the models, they can take a look at the Model Registry to find the new prod ready models\n",
    "\n",
    "The MLflow Model Registry component is a centralized model store, set of APIs, and UI, to collaboratively manage the full lifecycle of an MLflow Model. It provides model lineage (which MLflow experiment and run produced the model), model versioning, model aliasing, model tagging, and annotations.\n",
    "\n",
    "Model Registry does not deploy the models, instead it stores the models that are prod ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 14:42:21 INFO mlflow.tracking.fluent: Experiment with name 'taxi-model-registry' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/478746432289998830', creation_time=1725095541014, experiment_id='478746432289998830', last_update_time=1725095541014, lifecycle_stage='active', name='taxi-model-registry', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Set our tracking server uri for logging\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000\")\n",
    "\n",
    "# Create a new MLflow Experiment - Inside an experiment, there will be Runs\n",
    "mlflow.set_experiment(\"taxi-model-registry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to read the data, preprocess it and return it\n",
    "def read_and_preprocess(filename):\n",
    "    data = pd.read_parquet(filename)\n",
    "    \n",
    "    # create the target variable\n",
    "    data['ride_duration'] = data['tpep_dropoff_datetime'] - data['tpep_pickup_datetime'] \n",
    "    data['ride_duration'] = data['ride_duration'].apply(lambda x: x.total_seconds()/60) \n",
    "\n",
    "    # take only the data below 1 hour\n",
    "    data = data[(data['ride_duration'] >= 1) & (data['ride_duration'] <= 60)]\n",
    "\n",
    "    # # sample the data to 70k rows\n",
    "    # if len(data) > 70000:\n",
    "    #     sampled_data = data.iloc[:70000,:].copy()\n",
    "    # else:\n",
    "    #     sampled_data = data.copy()\n",
    "    sampled_data = data.copy()\n",
    "    \n",
    "    # chosing categorical\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "\n",
    "    # convert these numerical categorical features to string categorical features\n",
    "    sampled_data[categorical] = sampled_data[categorical].astype(str)\n",
    "\n",
    "    return sampled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_and_preprocess('../01-intro/data/yellow_tripdata_2021-01.parquet')\n",
    "df_valid = read_and_preprocess('../01-intro/data/yellow_tripdata_2021-02.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chosing categorical and numerical features\n",
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "numerical = ['trip_distance']\n",
    "\n",
    "# to use the DictVectorizer, we need to convert the dataframe to dict\n",
    "train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "val_dicts = df_valid[categorical + numerical].to_dict(orient='records')\n",
    "\n",
    "\n",
    "dv = DictVectorizer()\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "X_valid = dv.fit_transform(val_dicts)\n",
    "\n",
    "# storing our target variable\n",
    "target = 'ride_duration'\n",
    "y_train = df_train[target].values\n",
    "y_val = df_valid[target].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLFlow AutoLog, logs the following\n",
    "\n",
    "- Metrics - MLflow pre-selects a set of metrics to log, based on what model and library you use\n",
    "\n",
    "- Parameters - hyper params specified for the training, plus default values provided by the library if not explicitly set\n",
    "\n",
    "- Model Signature - logs Model signature instance, which describes input and output schema of the model\n",
    "\n",
    "- Artifacts - e.g. model checkpoints\n",
    "\n",
    "- Dataset - dataset object used for training (if applicable), such as tensorflow.data.Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 15:08:11 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2024/08/31 15:08:11 INFO mlflow.tracking.fluent: Autologging successfully enabled for lightgbm.\n",
      "2024/08/31 15:08:11 INFO mlflow.tracking.fluent: Autologging successfully enabled for xgboost.\n",
      "2024/08/31 15:08:14 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'numpy.ndarray' object has no attribute 'toarray'\n",
      "2024/08/31 15:08:21 INFO mlflow.tracking._tracking_service.client: üèÉ View run agreeable-skink-171 at: http://127.0.0.1:5000/#/experiments/478746432289998830/runs/47ec2cd3efd744f398c9381cfab20f6d.\n",
      "2024/08/31 15:08:21 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:5000/#/experiments/478746432289998830.\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression Model\n",
    "mlflow.autolog()\n",
    "\n",
    "# as we are using Auto Log, we do not need any \"with context manager\" but if we dont use context manager, we need to specify mflow.end_run() after each run\n",
    "# here this cell is a single run, so at end of the end, we need to specifu mlflow.end_run() if not using context manager\n",
    "with mlflow.start_run():\n",
    "    # train a LinearRegression Model\n",
    "    lr = LinearRegression()\n",
    "\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    # make predictions on test_data\n",
    "    y_pred = lr.predict(X_valid)\n",
    "\n",
    "    # calculate the metrics\n",
    "    rmse = root_mean_squared_error(y_val, y_pred) # squared set to False implies we are using RMSE instead MSE\n",
    "\n",
    "    # logging test metric\n",
    "    mlflow.log_metric('test_root_mean_squared_error', rmse)\n",
    "\n",
    "    # logging model name - Logging it as Param, so I can see a graph of models vs RMSE\n",
    "    mlflow.log_param('model','Linear Regression')\n",
    "\n",
    "# if not using with context manager, uncomment\n",
    "# mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 15:08:30 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'numpy.ndarray' object has no attribute 'toarray'\n",
      "2024/08/31 15:08:37 INFO mlflow.tracking._tracking_service.client: üèÉ View run loud-lark-824 at: http://127.0.0.1:5000/#/experiments/478746432289998830/runs/4aa4fd9eb7454abda7b05bacc5707262.\n",
      "2024/08/31 15:08:37 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:5000/#/experiments/478746432289998830.\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression Model with LASSO Regularization\n",
    "with mlflow.start_run():\n",
    "    lr = Lasso()\n",
    "\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    # make predictions on test_data\n",
    "    y_pred = lr.predict(X_valid)\n",
    "\n",
    "    # calculate the metrics\n",
    "    rmse = root_mean_squared_error(y_val, y_pred) # squared set to False implies we are using RMSE instead MSE\n",
    "\n",
    "    # logging test metric\n",
    "    mlflow.log_metric('test_root_mean_squared_error', rmse)\n",
    "\n",
    "    # logging model name - Logging it as Param, so I can see a graph of models vs RMSE\n",
    "    mlflow.log_param('model','LASSO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 15:08:46 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'numpy.ndarray' object has no attribute 'toarray'\n",
      "2024/08/31 15:08:53 INFO mlflow.tracking._tracking_service.client: üèÉ View run overjoyed-hare-3 at: http://127.0.0.1:5000/#/experiments/478746432289998830/runs/6abd28401d724ef8be3282d8942d8a5a.\n",
      "2024/08/31 15:08:53 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:5000/#/experiments/478746432289998830.\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression Model with Ridge Regularization\n",
    "with mlflow.start_run():\n",
    "    # train a LinearRegression Model\n",
    "    lr = Ridge()\n",
    "\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    # make predictions on test_data\n",
    "    y_pred = lr.predict(X_valid)\n",
    "\n",
    "    # calculate the metrics\n",
    "    root_mean_squared_error(y_val, y_pred)\n",
    "\n",
    "    # calculate the metrics\n",
    "    rmse = root_mean_squared_error(y_val, y_pred) # squared set to False implies we are using RMSE instead MSE\n",
    "\n",
    "    # logging test metric\n",
    "    mlflow.log_metric('test_root_mean_squared_error', rmse)\n",
    "\n",
    "    # logging model name - Logging it as Param, so I can see a graph of models vs RMSE\n",
    "    mlflow.log_param('model','Ridge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost Regressor\n",
    "\n",
    "- n_estimators: The number of trees in the ensemble, often increased until no further improvements are seen.\n",
    "- max_depth: The maximum depth of each tree, often values are between 1 and 10.\n",
    "- eta: The learning rate used to weight each model, often set to small values such as 0.3, 0.1, 0.01, or smaller.\n",
    "- subsample: The number of samples (rows) used in each tree, set to a value between 0 and 1, often 1.0 to use all samples.\n",
    "- colsample_bytree: Number of features (columns) used in each tree, set to a value between 0 and 1, often 1.0 to use all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:14:43] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "2024/08/31 15:14:55 INFO mlflow.tracking._tracking_service.client: üèÉ View run fearless-fawn-503 at: http://127.0.0.1:5000/#/experiments/478746432289998830/runs/b838e9d27ae04a2f9fc8b8b34c767d57.\n",
      "2024/08/31 15:14:55 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:5000/#/experiments/478746432289998830.\n"
     ]
    }
   ],
   "source": [
    "# XGBoost Regressor\n",
    "with mlflow.start_run():\n",
    "    boost = XGBRegressor(n_estimators=1000, max_depth=7, eta=0.1, subsample=0.7, colsample_bytree=0.8)\n",
    "\n",
    "    boost.fit(X_train, y_train)\n",
    "\n",
    "    # make predictions on test_data\n",
    "    y_pred = boost.predict(X_valid)\n",
    "\n",
    "    # calculate the metrics\n",
    "    root_mean_squared_error(y_val, y_pred)\n",
    "\n",
    "    # calculate the metrics\n",
    "    rmse = root_mean_squared_error(y_val, y_pred) # squared set to False implies we are using RMSE instead MSE\n",
    "\n",
    "    # logging test metric\n",
    "    mlflow.log_metric('test_root_mean_squared_error', rmse)\n",
    "\n",
    "    # logging model name - Logging it as Param, so I can see a graph of models vs RMSE\n",
    "    mlflow.log_param('model','XGBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Run: data=<RunData: metrics={'test_root_mean_squared_error': 4.517709979174692}, params={'base_score': 'None',\n",
      " 'booster': 'None',\n",
      " 'colsample_bylevel': 'None',\n",
      " 'colsample_bynode': 'None',\n",
      " 'colsample_bytree': '0.8',\n",
      " 'custom_metric': 'None',\n",
      " 'device': 'None',\n",
      " 'early_stopping_rounds': 'None',\n",
      " 'eta': '0.1',\n",
      " 'eval_metric': 'None',\n",
      " 'gamma': 'None',\n",
      " 'grow_policy': 'None',\n",
      " 'interaction_constraints': 'None',\n",
      " 'learning_rate': 'None',\n",
      " 'max_bin': 'None',\n",
      " 'max_cat_threshold': 'None',\n",
      " 'max_cat_to_onehot': 'None',\n",
      " 'max_delta_step': 'None',\n",
      " 'max_depth': '7',\n",
      " 'max_leaves': 'None',\n",
      " 'maximize': 'None',\n",
      " 'min_child_weight': 'None',\n",
      " 'model': 'Linear Regression',\n",
      " 'monotone_constraints': 'None',\n",
      " 'multi_strategy': 'None',\n",
      " 'n_jobs': 'None',\n",
      " 'num_boost_round': '1000',\n",
      " 'num_parallel_tree': 'None',\n",
      " 'objective': 'reg:squarederror',\n",
      " 'random_state': 'None',\n",
      " 'reg_alpha': 'None',\n",
      " 'reg_lambda': 'None',\n",
      " 'sampling_method': 'None',\n",
      " 'scale_pos_weight': 'None',\n",
      " 'subsample': '0.7',\n",
      " 'tree_method': 'None',\n",
      " 'validate_parameters': 'None',\n",
      " 'verbose_eval': 'True',\n",
      " 'verbosity': 'None'}, tags={'mlflow.log-model.history': '[{\"run_id\": \"f16c74caba6a4c6d91051499e17f14a6\", '\n",
      "                             '\"artifact_path\": \"model\", \"utc_time_created\": '\n",
      "                             '\"2024-08-31 09:39:35.987789\", \"flavors\": '\n",
      "                             '{\"python_function\": {\"loader_module\": '\n",
      "                             '\"mlflow.xgboost\", \"python_version\": \"3.11.5\", '\n",
      "                             '\"data\": \"model.xgb\", \"env\": {\"conda\": '\n",
      "                             '\"conda.yaml\", \"virtualenv\": \"python_env.yaml\"}}, '\n",
      "                             '\"xgboost\": {\"xgb_version\": \"2.1.1\", \"data\": '\n",
      "                             '\"model.xgb\", \"model_class\": '\n",
      "                             '\"xgboost.sklearn.XGBRegressor\", \"model_format\": '\n",
      "                             '\"xgb\", \"code\": null}}, \"model_uuid\": '\n",
      "                             '\"8cd3bece719141c1adf3a7aaf00d80bd\"}]',\n",
      " 'mlflow.runName': 'likeable-turtle-73',\n",
      " 'mlflow.source.name': '/home/topisano/Desktop/projects/mlops-learning/venv/lib/python3.11/site-packages/ipykernel_launcher.py',\n",
      " 'mlflow.source.type': 'LOCAL',\n",
      " 'mlflow.user': 'topisano'}>, info=<RunInfo: artifact_uri='mlflow-artifacts:/478746432289998830/f16c74caba6a4c6d91051499e17f14a6/artifacts', end_time=1725097187818, experiment_id='478746432289998830', lifecycle_stage='active', run_id='f16c74caba6a4c6d91051499e17f14a6', run_name='likeable-turtle-73', run_uuid='f16c74caba6a4c6d91051499e17f14a6', start_time=1725097146761, status='FINISHED', user_id='topisano'>, inputs=<RunInputs: dataset_inputs=[<DatasetInput: dataset=<Dataset: digest='73555dd4', name='dataset', profile=('{\"features_shape\": [1340859, 519], \"features_size\": 695905821, '\n",
      " '\"features_nbytes\": 5567246568}'), schema=('{\"mlflow_tensorspec\": {\"features\": \"[{\\\\\"type\\\\\": \\\\\"tensor\\\\\", '\n",
      " '\\\\\"tensor-spec\\\\\": {\\\\\"dtype\\\\\": \\\\\"float64\\\\\", \\\\\"shape\\\\\": [-1, 519]}}]\", '\n",
      " '\"targets\": null}}'), source=('{\"tags\": {\"mlflow.user\": \"topisano\", \"mlflow.source.name\": '\n",
      " '\"/home/topisano/Desktop/projects/mlops-learning/venv/lib/python3.11/site-packages/ipykernel_launcher.py\", '\n",
      " '\"mlflow.source.type\": \"LOCAL\"}}'), source_type='code'>, tags=[<InputTag: key='mlflow.data.context', value='eval'>]>,\n",
      " <DatasetInput: dataset=<Dataset: digest='8748cccf', name='dataset', profile=('{\"features_shape\": [1343254, 519], \"features_size\": 697148826, '\n",
      " '\"features_nbytes\": 2788595304}'), schema=('{\"mlflow_tensorspec\": {\"features\": \"[{\\\\\"type\\\\\": \\\\\"tensor\\\\\", '\n",
      " '\\\\\"tensor-spec\\\\\": {\\\\\"dtype\\\\\": \\\\\"float32\\\\\", \\\\\"shape\\\\\": [-1, 519]}}]\", '\n",
      " '\"targets\": null}}'), source=('{\"tags\": {\"mlflow.user\": \"topisano\", \"mlflow.source.name\": '\n",
      " '\"/home/topisano/Desktop/projects/mlops-learning/venv/lib/python3.11/site-packages/ipykernel_launcher.py\", '\n",
      " '\"mlflow.source.type\": \"LOCAL\"}}'), source_type='code'>, tags=[<InputTag: key='mlflow.data.context', value='train'>]>]>>\n"
     ]
    }
   ],
   "source": [
    "# to get the information on last active run\n",
    "autolog_run = mlflow.last_active_run()\n",
    "print(autolog_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1343254, 519)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009066 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1245\n",
      "[LightGBM] [Info] Number of data points in the train set: 1343254, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 11.644064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 15:20:23 INFO mlflow.tracking._tracking_service.client: üèÉ View run intelligent-pig-197 at: http://127.0.0.1:5000/#/experiments/478746432289998830/runs/d1cc89c1a3064fb690b2e76058f06d57.\n",
      "2024/08/31 15:20:23 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:5000/#/experiments/478746432289998830.\n"
     ]
    }
   ],
   "source": [
    "# LightGBM Regressor\n",
    "with mlflow.start_run():\n",
    "    boost = LGBMRegressor()\n",
    "\n",
    "    boost.fit(X_train, y_train)\n",
    "\n",
    "    # make predictions on test_data\n",
    "    y_pred = boost.predict(X_valid)\n",
    "\n",
    "    # calculate the metrics\n",
    "    root_mean_squared_error(y_val, y_pred)\n",
    "\n",
    "    # calculate the metrics\n",
    "    rmse = root_mean_squared_error(y_val, y_pred) # squared set to False implies we are using RMSE instead MSE\n",
    "\n",
    "    # logging test metric\n",
    "    mlflow.log_metric('test_root_mean_squared_error', rmse)\n",
    "\n",
    "    # logging model name - Logging it as Param, so I can see a graph of models vs RMSE\n",
    "    mlflow.log_param('model','LGBMRegressor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "def print_auto_logged_info(run):\n",
    "    tags = {k: v for k, v in run.data.tags.items() if not k.startswith(\"mlflow.\")}\n",
    "    artifacts = [\n",
    "        f.path for f in mlflow.MlflowClient().list_artifacts(run.info.run_id, \"model\")\n",
    "    ]\n",
    "    feature_importances = [\n",
    "        f.path\n",
    "        for f in mlflow.MlflowClient().list_artifacts(run.info.run_id)\n",
    "        if f.path != \"model\"\n",
    "    ]\n",
    "    rprint(f\"run_id: {run.info.run_id}\")\n",
    "    rprint(f\"artifacts: {artifacts}\")\n",
    "    rprint(f\"feature_importances: {feature_importances}\")\n",
    "    rprint(f\"params: {run.data.params}\")\n",
    "    rprint(f\"metrics: {run.data.metrics}\")\n",
    "    rprint(f\"tags: {tags}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">run_id: d1cc89c1a3064fb690b2e76058f06d57\n",
       "</pre>\n"
      ],
      "text/plain": [
       "run_id: d1cc89c1a3064fb690b2e76058f06d57\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">artifacts: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'model/MLmodel'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model/conda.yaml'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model/model.pkl'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model/python_env.yaml'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'model/requirements.txt'</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "artifacts: \u001b[1m[\u001b[0m\u001b[32m'model/MLmodel'\u001b[0m, \u001b[32m'model/conda.yaml'\u001b[0m, \u001b[32m'model/model.pkl'\u001b[0m, \u001b[32m'model/python_env.yaml'\u001b[0m, \n",
       "\u001b[32m'model/requirements.txt'\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">feature_importances: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'feature_importance_gain.json'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'feature_importance_gain.png'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'feature_importance_split.json'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'feature_importance_split.png'</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "feature_importances: \u001b[1m[\u001b[0m\u001b[32m'feature_importance_gain.json'\u001b[0m, \u001b[32m'feature_importance_gain.png'\u001b[0m, \n",
       "\u001b[32m'feature_importance_split.json'\u001b[0m, \u001b[32m'feature_importance_split.png'\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">params: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'num_boost_round'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'100'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'reg_lambda'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'0.0'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'objective'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'regression'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'min_split_gain'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'0.0'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'subsample_freq'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'0'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'subsample'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1.0'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'num_leaves'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'31'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'LGBMRegressor'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'categorical_feature'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'auto'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'learning_rate'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'0.1'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'min_child_samples'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'20'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'feature_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'auto'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'random_state'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'None'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'min_child_weight'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'0.001'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'metric'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"['regression']\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'keep_training_booster'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'False'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'num_threads'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'8'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'reg_alpha'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'0.0'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'max_depth'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'-1'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'colsample_bytree'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1.0'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'boosting_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gbdt'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'subsample_for_bin'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'200000'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "params: \u001b[1m{\u001b[0m\u001b[32m'num_boost_round'\u001b[0m: \u001b[32m'100'\u001b[0m, \u001b[32m'reg_lambda'\u001b[0m: \u001b[32m'0.0'\u001b[0m, \u001b[32m'objective'\u001b[0m: \u001b[32m'regression'\u001b[0m, \u001b[32m'min_split_gain'\u001b[0m: \u001b[32m'0.0'\u001b[0m, \n",
       "\u001b[32m'subsample_freq'\u001b[0m: \u001b[32m'0'\u001b[0m, \u001b[32m'subsample'\u001b[0m: \u001b[32m'1.0'\u001b[0m, \u001b[32m'num_leaves'\u001b[0m: \u001b[32m'31'\u001b[0m, \u001b[32m'model'\u001b[0m: \u001b[32m'LGBMRegressor'\u001b[0m, \u001b[32m'categorical_feature'\u001b[0m: \n",
       "\u001b[32m'auto'\u001b[0m, \u001b[32m'learning_rate'\u001b[0m: \u001b[32m'0.1'\u001b[0m, \u001b[32m'min_child_samples'\u001b[0m: \u001b[32m'20'\u001b[0m, \u001b[32m'feature_name'\u001b[0m: \u001b[32m'auto'\u001b[0m, \u001b[32m'random_state'\u001b[0m: \u001b[32m'None'\u001b[0m, \n",
       "\u001b[32m'min_child_weight'\u001b[0m: \u001b[32m'0.001'\u001b[0m, \u001b[32m'metric'\u001b[0m: \u001b[32m\"\u001b[0m\u001b[32m[\u001b[0m\u001b[32m'regression'\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\"\u001b[0m, \u001b[32m'keep_training_booster'\u001b[0m: \u001b[32m'False'\u001b[0m, \u001b[32m'num_threads'\u001b[0m: \u001b[32m'8'\u001b[0m, \n",
       "\u001b[32m'reg_alpha'\u001b[0m: \u001b[32m'0.0'\u001b[0m, \u001b[32m'max_depth'\u001b[0m: \u001b[32m'-1'\u001b[0m, \u001b[32m'colsample_bytree'\u001b[0m: \u001b[32m'1.0'\u001b[0m, \u001b[32m'boosting_type'\u001b[0m: \u001b[32m'gbdt'\u001b[0m, \u001b[32m'subsample_for_bin'\u001b[0m: \n",
       "\u001b[32m'200000'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">metrics: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'test_root_mean_squared_error'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.555352288314773</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "metrics: \u001b[1m{\u001b[0m\u001b[32m'test_root_mean_squared_error'\u001b[0m: \u001b[1;36m4.555352288314773\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">tags: <span style=\"font-weight: bold\">{}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "tags: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fetch the auto logged parameters and metrics\n",
    "autolog_run = mlflow.last_active_run()\n",
    "# print_auto_logged_info(mlflow.get_run(run_id=autolog_run.info.run_id))\n",
    "print_auto_logged_info(autolog_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we see that autolog logs all the parameters of that model. And different metrics(for lightgbm it doesnt log any metrics, but for other sklearn models it logs different metrics like rmse, r2, etc and all these are for training data)\n",
    "\n",
    "We see all the artifacts that are saved in the artifacts folder. The model is saved in pkl format along with yaml files and requirement files to run the model\n",
    "\n",
    "Even Feature Importance data is stored which contains the feature imporatnce for different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Models from MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are Two Flavours / Methods to Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/topisano/Desktop/projects/mlops-learning/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 859.45it/s]  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(4.555352288314773)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model for inference\n",
    "\n",
    "# let the last run, LightGBM as trained at the last\n",
    "last_active_run = mlflow.last_active_run()\n",
    "\n",
    "# get the run id for this run\n",
    "run_id = last_active_run.info.run_id\n",
    "\n",
    "# to load any model, we need a model URI, for this we need the model run_id\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "\n",
    "# we need the run_id because the model is stored in mlartifacts/experiment_id/run_id/model folder. This folder contains the pkl file and all other\n",
    "# files which are shown in the above 2nd print statement\n",
    "\n",
    "# load the model using mlflow.lightgbm.model class and the URI\n",
    "loaded_model = mlflow.lightgbm.load_model(model_uri)\n",
    "\n",
    "y_pred = loaded_model.predict(X_valid)\n",
    "\n",
    "root_mean_squared_error(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 179.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(4.555352288314773)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the Model as a PyFunction instead XGBoost\n",
    "loaded_model = mlflow.pyfunc.load_model(model_uri)\n",
    "\n",
    "y_pred = loaded_model.predict(X_valid)\n",
    "\n",
    "root_mean_squared_error(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parent and Child Runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autologging for estimators (e.g. LinearRegression, Lasso) and meta estimators (e.g. Pipeline) creates a single run and logs. Autologging for parameter search estimators (e.g. GridSearchCV) creates a single parent run and nested child runs\n",
    "\n",
    "As we are using GridSearch, we will get multiple runs here. And for  each run, its parameters and scores will be logged. Also in the artifacts, the model with best score will be logged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 16:53:15 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'numpy.ndarray' object has no attribute 'toarray'\n",
      "2024/08/31 16:58:39 INFO mlflow.sklearn.utils: Logging the 5 best runs, 11 runs will be omitted.\n",
      "2024/08/31 16:58:39 INFO mlflow.tracking._tracking_service.client: üèÉ View run amusing-ant-749 at: http://127.0.0.1:5000/#/experiments/478746432289998830/runs/c7fac24d7e914aeb8239e40b11675ecb.\n",
      "2024/08/31 16:58:39 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:5000/#/experiments/478746432289998830.\n",
      "2024/08/31 16:58:39 INFO mlflow.tracking._tracking_service.client: üèÉ View run amusing-boar-204 at: http://127.0.0.1:5000/#/experiments/478746432289998830/runs/9bdce9b8a1004e03a2589a53d23920d4.\n",
      "2024/08/31 16:58:39 INFO mlflow.tracking._tracking_service.client: üèÉ View run masked-crane-442 at: http://127.0.0.1:5000/#/experiments/478746432289998830/runs/ea3cef248bcb431e86c5d94a5d8d1fbd.\n",
      "2024/08/31 16:58:39 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:5000/#/experiments/478746432289998830.\n",
      "2024/08/31 16:58:39 INFO mlflow.tracking._tracking_service.client: üèÉ View run rare-snake-918 at: http://127.0.0.1:5000/#/experiments/478746432289998830/runs/9a8404f8e28441f8a0c43c5ef8747944.\n",
      "2024/08/31 16:58:39 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:5000/#/experiments/478746432289998830.\n",
      "2024/08/31 16:58:39 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:5000/#/experiments/478746432289998830.\n",
      "2024/08/31 16:58:39 INFO mlflow.tracking._tracking_service.client: üèÉ View run nervous-fox-460 at: http://127.0.0.1:5000/#/experiments/478746432289998830/runs/1c3cd030d27b45a2acee85067b132bae.\n",
      "2024/08/31 16:58:39 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:5000/#/experiments/478746432289998830.\n",
      "2024/08/31 16:58:53 INFO mlflow.tracking._tracking_service.client: üèÉ View run bustling-calf-74 at: http://127.0.0.1:5000/#/experiments/478746432289998830/runs/e44817cfcd3443619a21c773a14fa106.\n",
      "2024/08/31 16:58:53 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:5000/#/experiments/478746432289998830.\n"
     ]
    }
   ],
   "source": [
    "# XGBoost Regressor with GridSearch\n",
    "with mlflow.start_run():\n",
    "    XGBR = XGBRegressor(colsample_bytree=0.8)\n",
    "\n",
    "    parameters = {'eta': [0.1,0.05],\n",
    "                  'subsample'    : [0.9, 0.5],\n",
    "                  'n_estimators' : [500,1000],\n",
    "                  'max_depth'    : [4,7]\n",
    "                 }\n",
    "\n",
    "    grid_XGBR = GridSearchCV(estimator=XGBR, param_grid = parameters, cv = 2, n_jobs=-1)\n",
    "\n",
    "    # fitting the search\n",
    "    grid_XGBR.fit(X_train, y_train)\n",
    "\n",
    "    # make predictions on test_data\n",
    "    y_pred = grid_XGBR.predict(X_valid)\n",
    "\n",
    "    # calculate the metrics\n",
    "    root_mean_squared_error(y_val, y_pred)\n",
    "\n",
    "    # calculate the metrics\n",
    "    rmse = root_mean_squared_error(y_val, y_pred) # squared set to False implies we are using RMSE instead MSE\n",
    "\n",
    "    # logging test metric\n",
    "    mlflow.log_metric('test_root_mean_squared_error', rmse)\n",
    "\n",
    "    # logging model name - Logging it as Param, so I can see a graph of models vs RMSE\n",
    "    mlflow.log_param('model','XGBoost_with_GridSearch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">run_id: e44817cfcd3443619a21c773a14fa106\n",
       "</pre>\n"
      ],
      "text/plain": [
       "run_id: e44817cfcd3443619a21c773a14fa106\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">artifacts: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'model/MLmodel'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model/conda.yaml'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model/model.pkl'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model/python_env.yaml'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'model/requirements.txt'</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "artifacts: \u001b[1m[\u001b[0m\u001b[32m'model/MLmodel'\u001b[0m, \u001b[32m'model/conda.yaml'\u001b[0m, \u001b[32m'model/model.pkl'\u001b[0m, \u001b[32m'model/python_env.yaml'\u001b[0m, \n",
       "\u001b[32m'model/requirements.txt'\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">feature_importances: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'best_estimator'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'cv_results.csv'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'estimator.html'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'metric_info.json'</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "feature_importances: \u001b[1m[\u001b[0m\u001b[32m'best_estimator'\u001b[0m, \u001b[32m'cv_results.csv'\u001b[0m, \u001b[32m'estimator.html'\u001b[0m, \u001b[32m'metric_info.json'\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">params: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'error_score'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'nan'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'scoring'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'None'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'best_n_estimators'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1000'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'n_jobs'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'-1'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'XGBoost_with_GridSearch'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'best_subsample'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'0.9'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'refit'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'True'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'pre_dispatch'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2*n_jobs'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'return_train_score'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'False'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'cv'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'best_eta'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'0.1'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'verbose'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'0'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'best_max_depth'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'7'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'param_grid'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"{'eta': [0.1, 0.05], 'subsample': [0.9, 0.5], 'n_estimators': [500, 1000], 'max_depth': [4, 7]}\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'estimator'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'XGBRegressor(base_score=None, booster=None, callbacks=None,\\n             colsample_bylevel=None, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">colsample_bynode=None,\\n             colsample_bytree=0.8, device=None, early_stopping_rounds=None,\\n             </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enable_categorical=False, eval_metric=None, feature_types=None,\\n             gamma=None, grow_policy=None, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">importance_type=None,\\n             interaction_constraints=None, learning_rate=None, max_bin=None,\\n             </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">max_cat_threshold=None, max_cat_to_onehot=None,\\n             max_delta_step=None, max_depth=None, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">max_leaves=None,\\n             min_child_weight=None, missing=nan, monotone_constraints=None,\\n             </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">multi_strategy=None, n_estimators=None, n_jobs=None,\\n             num_parallel_tree=None, random_state=None, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">...)'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "params: \u001b[1m{\u001b[0m\u001b[32m'error_score'\u001b[0m: \u001b[32m'nan'\u001b[0m, \u001b[32m'scoring'\u001b[0m: \u001b[32m'None'\u001b[0m, \u001b[32m'best_n_estimators'\u001b[0m: \u001b[32m'1000'\u001b[0m, \u001b[32m'n_jobs'\u001b[0m: \u001b[32m'-1'\u001b[0m, \u001b[32m'model'\u001b[0m: \n",
       "\u001b[32m'XGBoost_with_GridSearch'\u001b[0m, \u001b[32m'best_subsample'\u001b[0m: \u001b[32m'0.9'\u001b[0m, \u001b[32m'refit'\u001b[0m: \u001b[32m'True'\u001b[0m, \u001b[32m'pre_dispatch'\u001b[0m: \u001b[32m'2*n_jobs'\u001b[0m, \n",
       "\u001b[32m'return_train_score'\u001b[0m: \u001b[32m'False'\u001b[0m, \u001b[32m'cv'\u001b[0m: \u001b[32m'2'\u001b[0m, \u001b[32m'best_eta'\u001b[0m: \u001b[32m'0.1'\u001b[0m, \u001b[32m'verbose'\u001b[0m: \u001b[32m'0'\u001b[0m, \u001b[32m'best_max_depth'\u001b[0m: \u001b[32m'7'\u001b[0m, \u001b[32m'param_grid'\u001b[0m: \n",
       "\u001b[32m\"\u001b[0m\u001b[32m{\u001b[0m\u001b[32m'eta': \u001b[0m\u001b[32m[\u001b[0m\u001b[32m0.1, 0.05\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, 'subsample': \u001b[0m\u001b[32m[\u001b[0m\u001b[32m0.9, 0.5\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, 'n_estimators': \u001b[0m\u001b[32m[\u001b[0m\u001b[32m500, 1000\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, 'max_depth': \u001b[0m\u001b[32m[\u001b[0m\u001b[32m4, 7\u001b[0m\u001b[32m]\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\"\u001b[0m, \u001b[32m'estimator'\u001b[0m: \n",
       "\u001b[32m'XGBRegressor\u001b[0m\u001b[32m(\u001b[0m\u001b[32mbase_score\u001b[0m\u001b[32m=\u001b[0m\u001b[32mNone\u001b[0m\u001b[32m, \u001b[0m\u001b[32mbooster\u001b[0m\u001b[32m=\u001b[0m\u001b[32mNone\u001b[0m\u001b[32m, \u001b[0m\u001b[32mcallbacks\u001b[0m\u001b[32m=\u001b[0m\u001b[32mNone\u001b[0m\u001b[32m,\\n             \u001b[0m\u001b[32mcolsample_bylevel\u001b[0m\u001b[32m=\u001b[0m\u001b[32mNone\u001b[0m\u001b[32m, \u001b[0m\n",
       "\u001b[32mcolsample_bynode\u001b[0m\u001b[32m=\u001b[0m\u001b[32mNone\u001b[0m\u001b[32m,\\n             \u001b[0m\u001b[32mcolsample_bytree\u001b[0m\u001b[32m=\u001b[0m\u001b[32m0\u001b[0m\u001b[32m.8, \u001b[0m\u001b[32mdevice\u001b[0m\u001b[32m=\u001b[0m\u001b[32mNone\u001b[0m\u001b[32m, \u001b[0m\u001b[32mearly_stopping_rounds\u001b[0m\u001b[32m=\u001b[0m\u001b[32mNone\u001b[0m\u001b[32m,\\n             \u001b[0m\n",
       "\u001b[32menable_categorical\u001b[0m\u001b[32m=\u001b[0m\u001b[32mFalse\u001b[0m\u001b[32m, \u001b[0m\u001b[32meval_metric\u001b[0m\u001b[32m=\u001b[0m\u001b[32mNone\u001b[0m\u001b[32m, \u001b[0m\u001b[32mfeature_types\u001b[0m\u001b[32m=\u001b[0m\u001b[32mNone\u001b[0m\u001b[32m,\\n             \u001b[0m\u001b[32mgamma\u001b[0m\u001b[32m=\u001b[0m\u001b[32mNone\u001b[0m\u001b[32m, \u001b[0m\u001b[32mgrow_policy\u001b[0m\u001b[32m=\u001b[0m\u001b[32mNone\u001b[0m\u001b[32m, \u001b[0m\n",
       "\u001b[32mimportance_type\u001b[0m\u001b[32m=\u001b[0m\u001b[32mNone\u001b[0m\u001b[32m,\\n             \u001b[0m\u001b[32minteraction_constraints\u001b[0m\u001b[32m=\u001b[0m\u001b[32mNone\u001b[0m\u001b[32m, \u001b[0m\u001b[32mlearning_rate\u001b[0m\u001b[32m=\u001b[0m\u001b[32mNone\u001b[0m\u001b[32m, \u001b[0m\u001b[32mmax_bin\u001b[0m\u001b[32m=\u001b[0m\u001b[32mNone\u001b[0m\u001b[32m,\\n             \u001b[0m\n",
       "\u001b[32mmax_cat_threshold\u001b[0m\u001b[32m=\u001b[0m\u001b[32mNone\u001b[0m\u001b[32m, \u001b[0m\u001b[32mmax_cat_to_onehot\u001b[0m\u001b[32m=\u001b[0m\u001b[32mNone\u001b[0m\u001b[32m,\\n             \u001b[0m\u001b[32mmax_delta_step\u001b[0m\u001b[32m=\u001b[0m\u001b[32mNone\u001b[0m\u001b[32m, \u001b[0m\u001b[32mmax_depth\u001b[0m\u001b[32m=\u001b[0m\u001b[32mNone\u001b[0m\u001b[32m, \u001b[0m\n",
       "\u001b[32mmax_leaves\u001b[0m\u001b[32m=\u001b[0m\u001b[32mNone\u001b[0m\u001b[32m,\\n             \u001b[0m\u001b[32mmin_child_weight\u001b[0m\u001b[32m=\u001b[0m\u001b[32mNone\u001b[0m\u001b[32m, \u001b[0m\u001b[32mmissing\u001b[0m\u001b[32m=\u001b[0m\u001b[32mnan\u001b[0m\u001b[32m, \u001b[0m\u001b[32mmonotone_constraints\u001b[0m\u001b[32m=\u001b[0m\u001b[32mNone\u001b[0m\u001b[32m,\\n             \u001b[0m\n",
       "\u001b[32mmulti_strategy\u001b[0m\u001b[32m=\u001b[0m\u001b[32mNone\u001b[0m\u001b[32m, \u001b[0m\u001b[32mn_estimators\u001b[0m\u001b[32m=\u001b[0m\u001b[32mNone\u001b[0m\u001b[32m, \u001b[0m\u001b[32mn_jobs\u001b[0m\u001b[32m=\u001b[0m\u001b[32mNone\u001b[0m\u001b[32m,\\n             \u001b[0m\u001b[32mnum_parallel_tree\u001b[0m\u001b[32m=\u001b[0m\u001b[32mNone\u001b[0m\u001b[32m, \u001b[0m\u001b[32mrandom_state\u001b[0m\u001b[32m=\u001b[0m\u001b[32mNone\u001b[0m\u001b[32m, \u001b[0m\n",
       "\u001b[32m...\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">metrics: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'training_mean_squared_error'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12.585850837020546</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'training_r2_score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8398602897961169</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'training_score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8398602897961169</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'best_cv_score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7799001969481429</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'root_mean_squared_error_X_valid'</span>: \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.530145579913529</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'test_root_mean_squared_error'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.530145579913529</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'training_mean_absolute_error'</span>: \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.3335392239876986</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'root_mean_squared_error-2_X_valid'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.530145579913529</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'training_root_mean_squared_error'</span>: \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.547654272476469</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "metrics: \u001b[1m{\u001b[0m\u001b[32m'training_mean_squared_error'\u001b[0m: \u001b[1;36m12.585850837020546\u001b[0m, \u001b[32m'training_r2_score'\u001b[0m: \u001b[1;36m0.8398602897961169\u001b[0m, \n",
       "\u001b[32m'training_score'\u001b[0m: \u001b[1;36m0.8398602897961169\u001b[0m, \u001b[32m'best_cv_score'\u001b[0m: \u001b[1;36m0.7799001969481429\u001b[0m, \u001b[32m'root_mean_squared_error_X_valid'\u001b[0m: \n",
       "\u001b[1;36m4.530145579913529\u001b[0m, \u001b[32m'test_root_mean_squared_error'\u001b[0m: \u001b[1;36m4.530145579913529\u001b[0m, \u001b[32m'training_mean_absolute_error'\u001b[0m: \n",
       "\u001b[1;36m2.3335392239876986\u001b[0m, \u001b[32m'root_mean_squared_error-2_X_valid'\u001b[0m: \u001b[1;36m4.530145579913529\u001b[0m, \u001b[32m'training_root_mean_squared_error'\u001b[0m: \n",
       "\u001b[1;36m3.547654272476469\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">tags: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'estimator_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'GridSearchCV'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'estimator_class'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'sklearn.model_selection._search.GridSearchCV'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "tags: \u001b[1m{\u001b[0m\u001b[32m'estimator_name'\u001b[0m: \u001b[32m'GridSearchCV'\u001b[0m, \u001b[32m'estimator_class'\u001b[0m: \u001b[32m'sklearn.model_selection._search.GridSearchCV'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lets Check the Logged Info\n",
    "\n",
    "# fetch the auto logged parameters and metrics\n",
    "autolog_run = mlflow.last_active_run()\n",
    "# print_auto_logged_info(mlflow.get_run(run_id=autolog_run.info.run_id))\n",
    "print_auto_logged_info(autolog_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In UI, if we go this run and check the artifacts, we get see a folder called `best_estimator` which stors the best model. The model folder also stores the same model. And looking above, in feature_importances, we can see a file called `cv results.csv`, This contains results like parameters, training error, cv error,etc  for all 16 different model configurations(as we have 4 parameters and each parameter has 2 different configurations, total search will be 2^4 = 16) that the GridSearchCV has comeup with\n",
    "\n",
    "MLFlow created 6 runs under the parent run. where these 6 runs are the top 6 configurations of the overall 16 configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Signature**\n",
    "The Model Signature in MLflow is integral to the clear and accurate operation of models. It defines the expected format for model inputs and outputs, including any additional parameters needed for inference. This specification acts as a definitive guide, ensuring seamless model integration with MLflow‚Äôs tools and external services.\n",
    "\n",
    "**Model Input Example**\n",
    "Complementing the Model Signature, the Model Input Example gives a concrete instance of what valid model input looks like.\n",
    "\n",
    "Mlflow's `autolog` automatically inferes the model signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://mlflow.org/docs/latest/_images/signature-vs-no-signature.png)\n",
    "\n",
    "Model signatures and input examples are foundational to robust ML workflows, offering a blueprint for model interactions that ensures consistency, accuracy, and ease of use. They act as a contract between the model and its users, providing a definitive guide to the expected data format, thus preventing miscommunication and errors that can arise from incorrect or unexpected inputs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
